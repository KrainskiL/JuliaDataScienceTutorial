{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73fcac75",
   "metadata": {},
   "source": [
    "# ML Models Deployment and Monitoring"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d046c8fb",
   "metadata": {},
   "source": [
    "## Model Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "191debd6",
   "metadata": {},
   "source": [
    "After training and evaluation, the model should be deployed to serve the predictions. The model is usually embedded into a bigger application or exposed through a web service. The mentioned solutions need additional logic to properly prepare the input data and return the prediction should be returned to the user in appropriate form. Let's consider two examples:\n",
    "* **JSON-based web service** - JSON payload with input observation is provided to the web service and the JSON with the prediction is returned back\n",
    "* **interactive web application with GUI** - the model is embedded into the application which gathers input from the set of text fields, sliders and other interactive elements, while the prediction is presented on the screen as part of the user interface\n",
    "\n",
    "As part of the notebook we'll build a simple web service working with JSON data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5370e1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Random, Logging\n",
    "using Statistics, StatsBase\n",
    "using CSV, DataFrames\n",
    "using Flux\n",
    "using BSON: @save, @load\n",
    "using JSON, HTTP\n",
    "using Plots\n",
    "using ProgressMeter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1678d6bf",
   "metadata": {},
   "source": [
    "We'll build regression model to predict median house value in the Boston suburbs. The dataset comes from [UCI repository](https://archive.ics.uci.edu/ml/machine-learning-databases/housing/).\n",
    "\n",
    "Attribute Information:\n",
    "\n",
    "1. CRIM - per capita crime rate by town\n",
    "2. ZN - proportion of residential land zoned for lots over 25,000 sq.ft.\n",
    "3. INDUS - proportion of non-retail business acres per town\n",
    "4. CHAS - Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
    "5. NOX - nitric oxides concentration (parts per 10 million)\n",
    "6. RM - average number of rooms per dwelling\n",
    "7. AGE - proportion of owner-occupied units built prior to 1940\n",
    "8. DIS - weighted distances to five Boston employment centres\n",
    "9. RAD - index of accessibility to radial highways\n",
    "10. TAX - full-value property-tax rate per \\$10,000\n",
    "11. PTRATIO - pupil-teacher ratio by town\n",
    "12. B - 1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
    "13. LSTAT - \\% lower status of the population\n",
    "14. **MEDV - Median value of owner-occupied homes in \\$1000's**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66331bc4",
   "metadata": {},
   "source": [
    "Load the Boston housing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d814b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "houses = CSV.read(\"Boston.csv\", DataFrame)\n",
    "select!(houses, Not(:Column1))\n",
    "X = transpose(Matrix(houses[!, Not(:medv)]))\n",
    "y = transpose(houses.medv);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b4af16",
   "metadata": {},
   "source": [
    "Let's build the neural network model with one dense hidden layer and ReLU activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3f39b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Chain(Dense(13 => 42, relu), Dense(42 => 1))\n",
    "loss(x, y) = Flux.Losses.mse(model(x), y)\n",
    "parameters = Flux.params(model)\n",
    "data = [(X, y)]\n",
    "opt = Flux.Adam(0.002)\n",
    "@showprogress for epoch in 1:50_000\n",
    "    Flux.train!(loss, parameters, data, opt)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba89cef6",
   "metadata": {},
   "source": [
    "Our main focus is to deploy the model, but it would be good to get the glimpse of the model's predictive power. We'll calculate Root Mean Squared Error of the neural network on the training data and compare it with the mean `MEDV` value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e02fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "RMSE(y, ŷ) = sqrt(mean((y-ŷ).^2))\n",
    "print(\"RMSE of the model is: \",RMSE(y, model(X)), \"\\nAverage MEDV is $(mean(y))\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b159d1",
   "metadata": {},
   "source": [
    "Save the model to `boston_nn.bson` file for further deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c01b794",
   "metadata": {},
   "outputs": [],
   "source": [
    "@save \"boston_nn.bson\" model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab531f4",
   "metadata": {},
   "source": [
    "Let's 'reset' the model variable with `nothing` and load Flux model from the file. The neural network generates the predictions, so the model was restored successfully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda5bc98",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nothing\n",
    "@load \"boston_nn.bson\" model\n",
    "model(X[:, 1])[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea5d778",
   "metadata": {},
   "source": [
    "We'll use the saved model in a web service build with [Genie.jl](https://github.com/GenieFramework/Genie.jl). `Genie` is part of broader `GenieFramework` environment providing tools for web development in Julia. \n",
    "\n",
    "Our small app will accept JSON payload with values of independent variables (crim, zn, indus, chas, nox, rm, age, dis, rad, tax, ptratio, black, lstat) and use it to produce a median house value prediction. The output will be send back in a JSON form as well. Let's save the first observation from the training dataset into `house.json` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f7d309",
   "metadata": {},
   "outputs": [],
   "source": [
    "open(\"house.json\",\"w\") do f\n",
    "    JSON.print(f, Dict(names(houses)[begin:end-1] .=> X[:, 1]), 4)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d6b2c9",
   "metadata": {},
   "source": [
    "The script below set up a basic web server accepting GET and POST requests under http://localhost:8000/ address."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6dc8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Flux\n",
    "using BSON: @load\n",
    "using Genie, Genie.Requests, Genie.Renderer.Json\n",
    "\n",
    "columns = [\"crim\",\"zn\",\"indus\",\"chas\",\"nox\",\"rm\",\"age\",\"dis\",\"rad\",\"tax\",\"ptratio\",\"black\",\"lstat\"]\n",
    "@load \"boston_nn.bson\" model\n",
    "\n",
    "route(\"/\") do\n",
    "\"\"\"<div style=\"white-space:pre\">To receive a prediction send POST request with JSON payload.\n",
    "\n",
    "Example:\n",
    ">> curl -X POST -d @house.json -H \"Content-Type: application/json\" http://localhost:8000/\n",
    ">> cat house.json\n",
    "{\n",
    "    \"crim\": 0.00632,\n",
    "    \"tax\": 296.0,\n",
    "    \"chas\": 0.0,\n",
    "    \"black\": 396.9,\n",
    "    \"lstat\": 4.98,\n",
    "    \"age\": 65.2,\n",
    "    \"indus\": 2.31,\n",
    "    \"rm\": 6.575,\n",
    "    \"dis\": 4.09,\n",
    "    \"zn\": 18.0,\n",
    "    \"nox\": 0.538,\n",
    "    \"ptratio\": 15.3,\n",
    "    \"rad\": 1.0\n",
    "}</div>\"\"\"\n",
    "end\n",
    "\n",
    "route(\"/\", method = POST) do\n",
    "    input_data = jsonpayload()\n",
    "    keys_json = keys(input_data)\n",
    "    missing_fields = [k for k in columns if k ∉ keys_json]\n",
    "    \n",
    "    if length(missing_fields) != 0\n",
    "        missing_str = join(missing_fields, \",\")\n",
    "        Json.json(:error => \"The fields: $missing_str are missing from the JSON payload.\"*\n",
    "            \"The prediction can not be returned.\")\n",
    "    else\n",
    "        try\n",
    "            Json.json(Dict(\"input\" => input_data,\n",
    "                        \"prediction\" => model([input_data[f] for f in columns])[1])\n",
    "                     )\n",
    "        catch e\n",
    "            Json.json(:error => \"Ooops! There was a problem while generating a prediction.\")\n",
    "        end\n",
    "    end\n",
    "end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2480361",
   "metadata": {},
   "source": [
    "Start the server - it will not block the Jupyter due to `async=true`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f935f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "up(port=8000, async=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c8a5e8c",
   "metadata": {},
   "source": [
    "After starting the server, you can use `curl` or other tool capable of sending and receiving HTTP requests to interact with the neural network model. If you have the `curl` program a following instructions may be used to receive the prediction from the web server:\n",
    "\n",
    "```shell\n",
    "curl -X POST -d @house.json -H \"Content-Type: application/json\" http://localhost:8000/\n",
    "```\n",
    "\n",
    "Within Julia we can use the `HTTP` package for sending the requests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387ba3c6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "host = \"http://localhost:8000\"\n",
    "header = [\"Content-Type\" => \"application/json\"]\n",
    "payload = read(\"house.json\", String)\n",
    "HTTP.post(host, header, payload)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eeb091b",
   "metadata": {},
   "source": [
    "Change the contents of `house.json` file and rerun the call to the web service. Prediction changed accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea45f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "HTTP.post(host, header, payload)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "138f23b0",
   "metadata": {},
   "source": [
    "The server is running asynchronously in Jupyter. When you are finished, run the `down()` command to turn it off.\n",
    "\n",
    "Note that there is `boston_web_service.jl` script in the directory of this notebook. It makes sense to run the web app outside of the Jupyter and use the notebook to interact with the service. You can use the \n",
    "```shell\n",
    "julia boston_web_service.jl\n",
    "```\n",
    "command to launch the app in the terminal synchronously (it will block your terminal, you can then turn the server down by using CMD+C/Ctrl+C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb0f62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "down()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e05f726",
   "metadata": {},
   "source": [
    "We have an app ready to be published - right now we can only access our ML service locally, so it's still not very useful. The `boston_web_service.jl` can be deployed on a remote machine with the public IP, maybe we'd bind a DNS domain with the IP, so the service would be available under a nice address like http://boston-predict.com/. \n",
    "\n",
    "The server would require the setup of all dependencies and correct configuration, so there is additional effort to operationalize the app. With that approach scaling the service and applying changes (maybe next step is to add a graphical interface) would also be very tedious. Some of the problems can be alleviated by packaging the app into container such as [Docker container](https://www.docker.com/). Containerization is a modern technique for applications development - the application source code, configuration and all required dependencies are packed within an image which can be easily shared and run on multiple machines.\n",
    "\n",
    "`Genie` supports Docker-based workflows with dedicated functions for building and running the images. More details are available in [Genie tutorial](https://genieframework.github.io/Genie.jl/dev/tutorials/16--Using_Genie_With_Docker.html). **Note that you'll need [Docker Desktop](https://www.docker.com/products/docker-desktop/) installed to follow the tutorial.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004a20d8",
   "metadata": {},
   "source": [
    "## Model monitoring"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf48ce2e",
   "metadata": {},
   "source": [
    "After deploying the model, the maintanance and monitoring phase starts. From the technical perspective, the application need to handle all the incoming requests within reasonable time, provide appropiate error handling, stay stable within the normal usage, etc. \n",
    "\n",
    "Additionally, the model needs to be monitored with regard to predictive performance. The drift in the incoming data (changes in the distribution of the underlying features compared to the training dataset) may degrade the model's quality. The bussiness needs may change over time as well, which in some cases may require model retraining or redefinition of the task.\n",
    "\n",
    "In more complex deployments, multiple models are involved in the monitoring and maintance process. Usually the setup includes the 'leading' model and 'auxilary' models. Commonly used techniques include:\n",
    "* **champion-challenger approach** - the 'champion' model is serving the predictions as the best performing model and the model's quality metrics are gathered over time; periodically the 'challengers' are evaluated against the new data points; if a challanger scores better than the champion, it may replace it as a new champion and the process is continued\n",
    "* **multi-armed bandits** - there are multiple models capable of serving the prediction in the deployed solution; the leading model in terms of predictive quality handles more requests than the remaining models; often each model receives the probability of serving the prediction, where the leading model has the highest probability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa59355f",
   "metadata": {},
   "source": [
    "Linear neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1988b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lin = Chain(Dense(13 => 30), Dense(30 => 1))\n",
    "loss(x, y) = Flux.Losses.mse(model_lin(x), y)\n",
    "parameters = Flux.params(model_lin)\n",
    "data = [(X, y)]\n",
    "opt = Flux.Adam(0.002)\n",
    "@showprogress for epoch in 1:50_000\n",
    "    Flux.train!(loss, parameters, data, opt)\n",
    "end\n",
    "@save \"boston_nn_lin.bson\" model_lin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3fe96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "RMSE(y, model_lin(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d921d6ff",
   "metadata": {},
   "source": [
    "RMSE should be much worse than in our first model. Let's build additional neural network with 2 hidden layers and ReLU activation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e970a2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2hl = Chain(Dense(13 => 30, relu), Dense(30 => 10, relu), Dense(10 => 1))\n",
    "loss(x, y) = Flux.Losses.mse(model_2hl(x), y)\n",
    "parameters = Flux.params(model_2hl)\n",
    "data = [(X, y)]\n",
    "opt = Flux.Adam(0.002)\n",
    "@showprogress for epoch in 1:60_000\n",
    "    Flux.train!(loss, parameters, data, opt)\n",
    "end\n",
    "@save \"boston_nn_2hl.bson\" model_2hl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2903250f",
   "metadata": {},
   "outputs": [],
   "source": [
    "RMSE(y, model_2hl(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c528c39",
   "metadata": {},
   "source": [
    "Now we are ready to build epsilon greedy 3-armed bandit service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d35393",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Flux\n",
    "using BSON: @load\n",
    "using Genie, Genie.Requests, Genie.Renderer.Json\n",
    "\n",
    "columns = [\"crim\",\"zn\",\"indus\",\"chas\",\"nox\",\"rm\",\"age\",\"dis\",\"rad\",\"tax\",\"ptratio\",\"black\",\"lstat\"]\n",
    "@load \"boston_nn.bson\" model\n",
    "@load \"boston_nn_lin.bson\" model_lin\n",
    "@load \"boston_nn_2hl.bson\" model_2hl\n",
    "\n",
    "ϵ = 0.8\n",
    "global seed = 1\n",
    "bandits = [(\"ReLU NN\", model), \n",
    "            (\"Linear NN\", model_lin), \n",
    "            (\"NN with Two Hidden Layers\", model_2hl)]\n",
    "pick_probs = ϵ:(1-ϵ)/(length(bandits)-1):1.0\n",
    "\n",
    "route(\"/\") do\n",
    "\"\"\"<div style=\"white-space:pre\">To receive a prediction send POST request with JSON payload.\n",
    "\n",
    "Example:\n",
    ">> curl -X POST -d @house.json -H \"Content-Type: application/json\" http://localhost:8000/\n",
    ">> cat house.json\n",
    "{\n",
    "    \"crim\": 0.00632,\n",
    "    \"tax\": 296.0,\n",
    "    \"chas\": 0.0,\n",
    "    \"black\": 396.9,\n",
    "    \"lstat\": 4.98,\n",
    "    \"age\": 65.2,\n",
    "    \"indus\": 2.31,\n",
    "    \"rm\": 6.575,\n",
    "    \"dis\": 4.09,\n",
    "    \"zn\": 18.0,\n",
    "    \"nox\": 0.538,\n",
    "    \"ptratio\": 15.3,\n",
    "    \"rad\": 1.0\n",
    "}</div>\"\"\"\n",
    "end\n",
    "\n",
    "route(\"/reset\") do\n",
    "    global seed = 1\n",
    "    \"Resetting the RNG seed.\"\n",
    "end\n",
    "\n",
    "route(\"/\", method = POST) do\n",
    "    input_data = jsonpayload()\n",
    "    keys_json = keys(input_data)\n",
    "    missing_fields = [k for k in columns if k ∉ keys_json]\n",
    "    \n",
    "    if length(missing_fields) != 0\n",
    "        missing_str = join(missing_fields, \",\")\n",
    "        Json.json(:error => \"The fields: $missing_str are missing from the JSON payload.\"*\n",
    "            \"The prediction can not be returned.\")\n",
    "    else     \n",
    "        try\n",
    "            (bandit_name, bandit) = bandits[argmin(pick_probs .<= rand(Xoshiro(seed)))]\n",
    "            global seed += 1\n",
    "            Json.json(Dict(\"input\" => input_data,\n",
    "                        \"prediction\" => bandit([input_data[f] for f in columns])[1],\n",
    "                        \"model\" => bandit_name)\n",
    "                     )\n",
    "        catch e\n",
    "            Json.json(:error => \"Ooops! There was a problem while generating a prediction.\")\n",
    "        end\n",
    "    end\n",
    "end\n",
    "up(port=8000, async=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c89322",
   "metadata": {},
   "source": [
    "Run the POST call to the web server and see the modified output of the service - beside the prediction, the app is returning name of the model which served the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f9de51",
   "metadata": {},
   "outputs": [],
   "source": [
    "HTTP.post(host, header, payload)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5519f2d",
   "metadata": {},
   "source": [
    "Let's send 1000 requests to the server and summarize the count of predictions from each model on the barplot. Info-level logs from the server are disabled to make the output cleaner and `/reset` endpoint is used to set random seed in the running app to it's initial state - the requests will return reproducible results whenever cell below is run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffbfd9d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Logging.disable_logging(Logging.Info)\n",
    "HTTP.get(host*\"/reset\")\n",
    "models_pick = []\n",
    "@showprogress for _ in 1:1000\n",
    "    res = String(HTTP.post(host, header, payload).body);\n",
    "    push!(models_pick, JSON.parse(res)[\"model\"])\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90161028",
   "metadata": {},
   "source": [
    "The results are aligned with expectations - `ReLU NN` served 80% of requests, while other requests got evenly distributed between `Linear NN` and `NN with Two Hidden Layers`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1129ca31",
   "metadata": {},
   "outputs": [],
   "source": [
    "bar(countmap(models_pick), legend=false, ylabel=\"Model occurences\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f193b1b",
   "metadata": {},
   "source": [
    "You can also run the server outside Jupyter using\n",
    "```shell\n",
    "julia boston_multi_armed.jl\n",
    "```\n",
    "Tear the server down when finished."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d8dca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "down()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0886683b",
   "metadata": {},
   "source": [
    "*Preparation of this workshop has been supported by the Polish National Agency for Academic Exchange under the Strategic Partnerships programme, grant number BPI/PST/2021/1/00069/U/00001.*\n",
    "\n",
    "![SGH & NAWA](../logo.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.9.2",
   "language": "julia",
   "name": "julia-1.9"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
