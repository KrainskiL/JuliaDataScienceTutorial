{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73fcac75",
   "metadata": {},
   "source": [
    "# ML Models Deployment and Monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549bf40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the environment for the notebook from Project.toml and Manifest.toml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e58f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "]instantiate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d046c8fb",
   "metadata": {},
   "source": [
    "## Model Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "191debd6",
   "metadata": {},
   "source": [
    "After training and evaluation, the model should be deployed to serve the predictions. The model is usually embedded into a bigger application or exposed through a web service. The mentioned solutions need additional logic to properly prepare the input data and return the prediction should be returned to the user in appropriate form. Let's consider two examples:\n",
    "* **JSON-based web service** - JSON payload with input observation is provided to the web service and the JSON with the prediction is returned back\n",
    "* **interactive web application with GUI** - the model is embedded into the application which gathers input from the set of text fields, sliders and other interactive elements, while the prediction is presented on the screen as part of the user interface\n",
    "\n",
    "As part of the notebook we'll build a simple web service working with JSON data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5370e1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Random\n",
    "using Statistics\n",
    "using CSV\n",
    "using DataFrames\n",
    "using Flux\n",
    "using BSON: @save, @load\n",
    "using JSON\n",
    "using ProgressMeter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1678d6bf",
   "metadata": {},
   "source": [
    "We'll build regression model to predict median house value in the Boston suburbs. The dataset comes from [UCI repository](https://archive.ics.uci.edu/ml/machine-learning-databases/housing/).\n",
    "\n",
    "Attribute Information:\n",
    "\n",
    "1. CRIM - per capita crime rate by town\n",
    "2. ZN - proportion of residential land zoned for lots over 25,000 sq.ft.\n",
    "3. INDUS - proportion of non-retail business acres per town\n",
    "4. CHAS - Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
    "5. NOX - nitric oxides concentration (parts per 10 million)\n",
    "6. RM - average number of rooms per dwelling\n",
    "7. AGE - proportion of owner-occupied units built prior to 1940\n",
    "8. DIS - weighted distances to five Boston employment centres\n",
    "9. RAD - index of accessibility to radial highways\n",
    "10. TAX - full-value property-tax rate per \\$10,000\n",
    "11. PTRATIO - pupil-teacher ratio by town\n",
    "12. B - 1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
    "13. LSTAT - \\% lower status of the population\n",
    "14. **MEDV - Median value of owner-occupied homes in \\$1000's**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d814b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading Boston housing data\n",
    "houses = CSV.read(\"Boston.csv\", DataFrame)\n",
    "houses = houses[:, Not(:Column1)]\n",
    "X = transpose(Matrix(houses[!,Not(:medv)]))\n",
    "y = transpose(houses.medv);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3f39b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Neural network model one dense hidden layer with ReLU activation function\n",
    "model = Chain(Dense(13 => 42, relu), Dense(42 => 1))\n",
    "loss(x, y) = Flux.Losses.mse(model(x), y)\n",
    "parameters = Flux.params(model)\n",
    "data = [(X, y)]\n",
    "opt = Flux.Adam(0.002)\n",
    "@showprogress for epoch in 1:50_000\n",
    "    Flux.train!(loss, parameters, data, opt)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e02fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Auxilary function for Root Mean Squared Error calculation\n",
    "RMSE(y, ŷ) = sqrt(mean((y-ŷ).^2));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff91c78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RMSE of the neural network on the training data\n",
    "RMSE(y, model(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c01b794",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the model to `boston_nn.bson` file\n",
    "@save \"boston_nn.bson\" model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda5bc98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's 'reset' the model variable with nothing and load Flux model from the file\n",
    "model = nothing\n",
    "@load \"boston_nn.bson\" model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa292af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The neural network can generate the predictions after being loaded from the file\n",
    "model(X[:,1])[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea5d778",
   "metadata": {},
   "source": [
    "We'll use the saved model in a web service build with [Genie.jl](https://github.com/GenieFramework/Genie.jl). `Genie` is part of broader `GenieFramework` environment providing tools for web development in Julia. \n",
    "\n",
    "Our small app will accept JSON payload with values of independent variables (crim, zn, indus, chas, nox, rm, age, dis, rad, tax, ptratio, black, lstat) and use it to produce a median house value prediction. The output will be send back in a JSON form as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f7d309",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving first observation from the training dataset into `house.json` file\n",
    "open(\"house.json\",\"w\") do f\n",
    "    JSON.print(f, Dict(names(houses)[begin:end-1] .=> X[:,1]), 4)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6dc8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The script below set up a basic web server accepting GET and POST requests under http://localhost:8000/ address\n",
    "using Flux\n",
    "using BSON: @load\n",
    "using Genie, Genie.Requests, Genie.Renderer.Json\n",
    "\n",
    "columns = [\"crim\",\"zn\",\"indus\",\"chas\",\"nox\",\"rm\",\"age\",\"dis\",\"rad\",\"tax\",\"ptratio\",\"black\",\"lstat\"]\n",
    "@load \"boston_nn.bson\" model\n",
    "\n",
    "route(\"/\") do\n",
    "\"\"\"<div style=\"white-space:pre\">To receive a prediction send POST request with JSON payload.\n",
    "\n",
    "Example:\n",
    ">> curl -X POST -d @house.json -H \"Content-Type: application/json\" http://localhost:8000/\n",
    ">> cat house.json\n",
    "{\n",
    "    \"crim\": 0.00632,\n",
    "    \"tax\": 296.0,\n",
    "    \"chas\": 0.0,\n",
    "    \"black\": 396.9,\n",
    "    \"lstat\": 4.98,\n",
    "    \"age\": 65.2,\n",
    "    \"indus\": 2.31,\n",
    "    \"rm\": 6.575,\n",
    "    \"dis\": 4.09,\n",
    "    \"zn\": 18.0,\n",
    "    \"nox\": 0.538,\n",
    "    \"ptratio\": 15.3,\n",
    "    \"rad\": 1.0\n",
    "}</div>\"\"\"\n",
    "end\n",
    "\n",
    "route(\"/\", method = POST) do\n",
    "    input_data = jsonpayload()\n",
    "    keys_json = keys(input_data)\n",
    "    missing_fields = [k for k in columns if k ∉ keys_json]\n",
    "    \n",
    "    if length(missing_fields) != 0\n",
    "        missing_str = join(missing_fields, \",\")\n",
    "        Json.json(:error => \"The fields: $missing_str are missing from the JSON payload.\"*\n",
    "            \"The prediction can not be returned.\")\n",
    "    else\n",
    "        try\n",
    "            Json.json(Dict(\"input\" => input_data,\n",
    "                        \"prediction\" => model([input_data[f] for f in columns])[1])\n",
    "                     )\n",
    "        catch e\n",
    "            Json.json(:error => \"Ooops! There was a problem while generating a prediction.\")\n",
    "        end\n",
    "    end\n",
    "end\n",
    "#start the server - it will not block the Jupyter due to async=true\n",
    "up(port=8000, async=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c8a5e8c",
   "metadata": {},
   "source": [
    "After starting the server, you can use `curl` or other tool capable of sending and receiving HTTP requests to interact with the neural network model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f24666",
   "metadata": {},
   "outputs": [],
   "source": [
    ";curl -X POST -d @house.json -H \"Content-Type: application/json\" http://localhost:8000/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eeb091b",
   "metadata": {},
   "source": [
    "Change the contents of `house.json` file and rerun the call to the web service. Prediction changed accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea45f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    ";curl -X POST -d @house.json -H \"Content-Type: application/json\" http://localhost:8000/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "138f23b0",
   "metadata": {},
   "source": [
    "The server is running asynchronously in Jupyter. When you are finished, run the `down()` command to turn it off.\n",
    "\n",
    "Note that there is `boston_web_service.jl` script in the directory of this notebook. It makes sense to run the web app outside of the Jupyter and use the notebook to interact with the service. You can use the \n",
    "```shell\n",
    "julia boston_web_service.jl\n",
    "```\n",
    "command to launch the app in the terminal synchronously (it will block your terminal, you can then turn the server down by using CMD+C/Ctrl+C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb0f62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "down()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e05f726",
   "metadata": {},
   "source": [
    "We have an app ready to be published - right now we can only access our ML service locally, so it's still not very useful. The `boston_web_service.jl` can be deployed on a remote machine with the public IP, maybe we'd bind a DNS domain with the IP, so the service would be available under a nice address like http://boston-predict.com/. \n",
    "\n",
    "The server would require the setup of all dependencies and correct configuration, so there is additional effort to operationalize the app. With that approach scaling the service and applying changes (maybe next step is to add a graphical interface) would also be very tedious. Some of the problems can be alleviated by packaging the app into container such as [Docker container](https://www.docker.com/). Containerization is a modern technique for applications development - the application source code, configuration and all required dependencies are packed within an image which can be easily shared and run on multiple machines.\n",
    "\n",
    "`Genie` supports Docker-based workflows with dedicated functions for building and running the images. More details are available in [Genie tutorial](https://genieframework.github.io/Genie.jl/dev/tutorials/16--Using_Genie_With_Docker.html). **Note that you'll need [Docker Desktop](https://www.docker.com/products/docker-desktop/) installed to follow the tutorial.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004a20d8",
   "metadata": {},
   "source": [
    "## Model monitoring"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf48ce2e",
   "metadata": {},
   "source": [
    "After deploying the model, the maintanance and monitoring phase starts. From the technical perspective, the application need to handle all the incoming requests within reasonable time, provide appropiate error handling, stay stable within the normal usage, etc. \n",
    "\n",
    "Additionally, the model needs to be monitored with regard to predictive performance. The drift in the incoming data (changes in the distribution of the underlying features compared to the training dataset) may degrade the model's quality. The bussiness needs may change over time as well, which in some cases may require model retraining or redefinition of the task.\n",
    "\n",
    "In more complex deployments, multiple models are involved in the monitoring and maintance process. Usually the setup includes the 'leading' model and 'auxilary' models. Commonly used techniques include:\n",
    "* **champion-challenger approach** - the 'champion' model is serving the predictions as the best performing model and the model's quality metrics are gathered over time; periodically the 'challengers' are evaluated against the new data points; if a challanger scores better than the champion, it may replace it as a new champion and the process is continued\n",
    "* **multi-armed bandits** - there are multiple models capable of serving the prediction in the deployed solution; the leading model in terms of predictive quality handles more requests than the remaining models; often each model receives the probability of serving the prediction, where the leading model has the highest probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1988b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Linear neural network\n",
    "model_lin = Chain(Dense(13 => 30), Dense(30 => 1))\n",
    "loss(x, y) = Flux.Losses.mse(model_lin(x), y)\n",
    "parameters = Flux.params(model_lin)\n",
    "data = [(X, y)]\n",
    "opt = Flux.Adam(0.002)\n",
    "@showprogress for epoch in 1:50_000\n",
    "    Flux.train!(loss, parameters, data, opt)\n",
    "end\n",
    "@save \"boston_nn_lin.bson\" model_lin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3fe96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "RMSE(y, model_lin(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e970a2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Neural network with 2 hidden layers\n",
    "model_2hl = Chain(Dense(13 => 30, relu), Dense(30 => 10, relu), Dense(10 => 1))\n",
    "loss(x, y) = Flux.Losses.mse(model_2hl(x), y)\n",
    "parameters = Flux.params(model_2hl)\n",
    "data = [(X, y)]\n",
    "opt = Flux.Adam(0.002)\n",
    "@showprogress for epoch in 1:60_000\n",
    "    Flux.train!(loss, parameters, data, opt)\n",
    "end\n",
    "@save \"boston_nn_2hl.bson\" model_2hl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2903250f",
   "metadata": {},
   "outputs": [],
   "source": [
    "RMSE(y, model_2hl(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d35393",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Epsilon greedy 3-armed bandit\n",
    "using Flux\n",
    "using BSON: @load\n",
    "using Genie, Genie.Requests, Genie.Renderer.Json\n",
    "\n",
    "columns = [\"crim\",\"zn\",\"indus\",\"chas\",\"nox\",\"rm\",\"age\",\"dis\",\"rad\",\"tax\",\"ptratio\",\"black\",\"lstat\"]\n",
    "@load \"boston_nn.bson\" model\n",
    "@load \"boston_nn_lin.bson\" model_lin\n",
    "@load \"boston_nn_2hl.bson\" model_2hl\n",
    "\n",
    "ϵ = 0.5\n",
    "bandits = [(\"ReLU Neural Network\", model), \n",
    "            (\"Linear Neural Network\", model_lin), \n",
    "            (\"Neural Network with Two Hidden Layers\", model_2hl)]\n",
    "pick_probs = ϵ:ϵ/(length(bandits)-1):1.0\n",
    "\n",
    "route(\"/\", method = POST) do\n",
    "    input_data = jsonpayload()\n",
    "    keys_json = keys(input_data)\n",
    "    missing_fields = [k for k in columns if k ∉ keys_json]\n",
    "    \n",
    "    if length(missing_fields) != 0\n",
    "        missing_str = join(missing_fields, \",\")\n",
    "        Json.json(:error => \"The fields: $missing_str are missing from the JSON payload.\"*\n",
    "            \"The prediction can not be returned.\")\n",
    "    else     \n",
    "        try\n",
    "            (bandit_name, bandit) = bandits[argmin(pick_probs .<= rand())]\n",
    "            print(bandit_name)\n",
    "            Json.json(Dict(\"input\" => input_data,\n",
    "                        \"prediction\" => bandit([input_data[f] for f in columns])[1],\n",
    "                        \"model\" => bandit_name)\n",
    "                     )\n",
    "        catch e\n",
    "            Json.json(:error => \"Ooops! There was a problem while generating a prediction.\")\n",
    "        end\n",
    "    end\n",
    "end\n",
    "#start the server - it will not block the Jupyter due to async=true\n",
    "up(port=8000, async=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e123f9",
   "metadata": {},
   "source": [
    "Run few calls to the web server and see how the model serving the predictions change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed15351b",
   "metadata": {},
   "outputs": [],
   "source": [
    ";curl -X POST -d @house.json -H \"Content-Type: application/json\" http://localhost:8000/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f193b1b",
   "metadata": {},
   "source": [
    "You can also run the server outside Jupyter using\n",
    "```shell\n",
    "julia boston_multi_armed.jl\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d8dca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tear the server down when finished\n",
    "down()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.2",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
