{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f215af50",
   "metadata": {},
   "source": [
    "# Explaining The ML models - XAI (eXplainable AI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f491a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the environment for the notebook from Project.toml and Manifest.toml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c055823",
   "metadata": {},
   "outputs": [],
   "source": [
    "]instantiate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "107c53b4",
   "metadata": {},
   "source": [
    "Interpretation techniques for the ML models focus on analysis how input features (or change in their values) affect the predictions. Many classic models exhibit 'built-in' high interpretability by design, but the predictions of complex models such as neural networks are opaque (hence the often used name 'black-box' models). \n",
    "\n",
    "In the recent years, explainability of the ML models (black-box in particular) became a popular topic and fueled many novel algorithms - the trend is often referred to as **Interpretable Machine Learning** or **Explainable Artificial Intelligence (XAI)**. \n",
    "\n",
    "Based on the applicability, the interpretability techniques can be categorised as follows:\n",
    " - **model-specific (intrinsic)** - tied to particular class of models, inherently available by design of the given algorithm, e.g. linear regression, logistic regression, decision trees\n",
    " - **model-agnostic** - applicable to many model families, mostly based on modifying the input data and 'probing' the influence on model predictions or quality\n",
    "\n",
    "Additionally, the explainability algorithms may be broken down by the target they are applied to:\n",
    " - **prediction-level (local)** - provide explanation for prediction produced for a particular instance, useful if we want to understand the models behaviour on the per-case basis\n",
    " - **dataset-level (global)** - highlight overall feature influence on the model prediction\n",
    "\n",
    "Every interpretability technique is characterized by both breakdowns, so we may have a model-specific global technique, model-agnostic local algorithm, etc. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce802ef6",
   "metadata": {},
   "source": [
    "## Preparing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "941f6cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "using CSV\n",
    "using DataFrames\n",
    "using Random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba045724",
   "metadata": {},
   "source": [
    "We'll use dataset about housing in suburbs of Boston. You can find more information about the dataset in the [UCI repository](https://archive.ics.uci.edu/ml/machine-learning-databases/housing/). Data is available for ingestion in the **Boston.csv** file in the directory of the notebook.\n",
    "\n",
    "Attribute Information:\n",
    "\n",
    "1. CRIM - per capita crime rate by town\n",
    "2. ZN - proportion of residential land zoned for lots over 25,000 sq.ft.\n",
    "3. INDUS - proportion of non-retail business acres per town\n",
    "4. CHAS - Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
    "5. NOX - nitric oxides concentration (parts per 10 million)\n",
    "6. RM - average number of rooms per dwelling\n",
    "7. AGE - proportion of owner-occupied units built prior to 1940\n",
    "8. DIS - weighted distances to five Boston employment centres\n",
    "9. RAD - index of accessibility to radial highways\n",
    "10. TAX - full-value property-tax rate per \\$10,000\n",
    "11. PTRATIO - pupil-teacher ratio by town\n",
    "12. B - 1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
    "13. LSTAT - \\% lower status of the population\n",
    "14. MEDV - Median value of owner-occupied homes in \\$1000's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b7cf0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "houses = CSV.read(\"Boston.csv\", DataFrame);\n",
    "first(houses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ab3c11",
   "metadata": {},
   "source": [
    "Our task is to predict the median house value (MEDV) based on all other available features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c5106e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's remove the Column1 containing observation ID\n",
    "houses = houses[:, Not(:Column1)];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3d87b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = names(houses, Not(:medv))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c6cf01c",
   "metadata": {},
   "source": [
    "## Model-specific interpretability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054636cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "using GLM\n",
    "using XGBoost\n",
    "using Plots\n",
    "using Statistics\n",
    "using Random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4dfc5b",
   "metadata": {},
   "source": [
    "We'll train two models with 'built-in' (inherent) explainability: \n",
    "1. Linear Regression\n",
    "2. Gradient Boosted Trees\n",
    "\n",
    "In the first example, we'll **directly interpret the values of the parameters** for the trained model - this approach is applicable to the whole family of [**Generalized Linear Models (GLMs)**](https://en.wikipedia.org/wiki/Generalized_linear_model) with appropiate transformations applied to the parameters and target variable values, e.g. logistic regression, Poisson regression.\n",
    "\n",
    "**Gradient Boosted Trees** is part of the bigger family of **tree-based models** (which includes various Decision Trees algorithms and ensemble models such as Random Forest). For the tree-based models, we can calculate a **feature importance** - the metric of the features contribution to the quality of model fit to the training data. Often the  The parameter values are not analysed directly, instead we are extracting a statistic from training process which is relevant to understanding the model decisions. Values of feature importance are usually available in the attribute or method of the trained tree-based models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "346810b2",
   "metadata": {},
   "source": [
    "Please note that we are not splitting the dataset into training, validation and test subsets as we are not picking the optimal specifications of the models. The models predictive power is checked on the training data to validate the output of interpretability algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd46eace",
   "metadata": {},
   "source": [
    "### Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619c8853",
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_reg = lm(term(:medv) ~ sum(term.([1; feature_names])), houses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c794f12",
   "metadata": {},
   "source": [
    "We can directly interpret calculated coefficients as the change in the predicted value (median house value in thousands of dollars) for a unit change in the value of the feature.\n",
    "\n",
    "For example, prediction for median house value will increase by 3.800 dollars with each additional room in the estate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ec236d",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2(lin_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6fe612",
   "metadata": {},
   "source": [
    "R2 is quite high, hence the model is performing well (on the training data). \n",
    "It's important to check the model quality while analysing the effect of the features - if the model quality is low we may get incorrect picture of which features are important for the task in general."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdfb474e",
   "metadata": {},
   "source": [
    "### Gradient Boosted Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa4af9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = Matrix(houses[!,Not(:medv)])\n",
    "xgb_reg = xgboost(X, 40, label = houses.medv,\n",
    "                    objective = \"reg:squarederror\", seed = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39fbe2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating R^2 for trained XGBoost model\n",
    "#It's quite high, we may feel comfortable to look on the features importance\n",
    "R2(y, ŷ) = sum((ŷ .- mean(y)).^2)/sum((y .- mean(y)).^2)\n",
    "R2(houses.medv, XGBoost.predict(xgb_reg, X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b349857",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_imp = importance(xgb_reg, feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01cecda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot all variables and their feature importance on barplot (output from your own function)\n",
    "bar(getproperty.(f_imp, :fname), getproperty.(f_imp, :gain), \n",
    "         ylab=\"Feature gain\", legend=nothing, title=\"XGBoost feature importance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61083938",
   "metadata": {},
   "source": [
    "Based on the built-in feature importance two the most important features for model predictions are:\n",
    " - LSTAT\n",
    " - RM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd5f6ea",
   "metadata": {},
   "source": [
    "## Model-agnostic interpretability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6811fc",
   "metadata": {},
   "source": [
    "Model-agnostic algorithms may be applied on top of many Machine Learning models. It is possible as they operate by modifying the data input and analysing the returned predictions - the inner workings of the model is not relevant in that context. The model-agnostic techniques can be further divided into:\n",
    "\n",
    "Global techniques (explaining overall features effect on predictions):\n",
    "- [Partial Dependence Plots (PDP)](https://www.jstor.org/stable/2699986)\n",
    "- [Accumulated Local Effects (ALE)](https://arxiv.org/abs/1612.08468)\n",
    "- [Permutation-based feature importance](https://scikit-learn.org/stable/modules/permutation_importance.html)\n",
    "\n",
    "Local techniques (explaining particular prediction):\n",
    "- [Individual Conditional Expectations (ICE)](https://arxiv.org/abs/1309.6392)\n",
    "- [LIME (Local Interpretable Model-agnostic Explanations)](https://arxiv.org/abs/1602.04938)\n",
    "- [Shapley Values and SHAP (SHapley Additive exPlanations)](https://arxiv.org/abs/1705.07874)\n",
    "\n",
    "Let's explore one algorithm from each category: global **Permutation feature importance** and local **SHAP values**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ec9b76",
   "metadata": {},
   "source": [
    "### Permutation-based feature importance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed087df",
   "metadata": {},
   "source": [
    "The technique relies on measuring effect of breaking the relation between independent features and target variable. The idea is quite straightforward - if the important feature is randomly shuffled, the model performance should drop significantly, correspondingly for the not imporant feature the effect on the model's quality will be small. \n",
    "\n",
    "The algorithm can be applied to all models (model-agnostic) as it modify the data by shuffling the subsequent features and analyse the evaluation metric calculated based on predictions on the distorted data. Also the model is global as it provide importance per feature on the whole dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63005086",
   "metadata": {},
   "source": [
    "Let's implement our own algorithm for permutation feature importance based on RMSE metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48c4dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "RMSE(y, ŷ) = sqrt(mean((y-ŷ).^2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6e97e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "function varimp(df::DataFrame, \n",
    "        model::Booster, \n",
    "        name::Symbol, \n",
    "        ref_rmse::Float64, \n",
    "        reps::Int = 10,\n",
    "        random_seed::Int = 1)\n",
    "    df_shuffle = copy(df[:,1:end-1])\n",
    "    y = df[:,end]\n",
    "    rmse = []\n",
    "    for _ in 1:reps\n",
    "        Random.seed!(random_seed)\n",
    "        Random.shuffle!(df_shuffle[!, name])\n",
    "        X = Matrix(df_shuffle)\n",
    "        push!(rmse, RMSE(y,XGBoost.predict(xgb_reg, X)))\n",
    "    end\n",
    "    rmse = rmse .- ref_rmse\n",
    "    return (mean(rmse), std(rmse))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3456514d",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_rmse = RMSE(houses.medv,XGBoost.predict(xgb_reg, X))\n",
    "perm_feat_imp = []\n",
    "reps = 20\n",
    "for name in feature_names\n",
    "    (avg_rmse, std_rmse) = varimp(houses, xgb_reg, Symbol(name), xgb_rmse, reps, 42)\n",
    "    push!(perm_feat_imp,(feature=name, rmse_change=avg_rmse, rmse_std=std_rmse))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f6f7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "perm_ft = DataFrame(perm_feat_imp)\n",
    "sort!(perm_ft, :rmse_change, rev=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80021e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "bar(perm_ft.feature,\n",
    "    perm_ft.rmse_change,\n",
    "    yerr = perm_ft.rmse_std,\n",
    "    legend = nothing,\n",
    "    ylab=\"RMSE change\", title=\"Permutation-based feature importance ($reps reps)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e950d702",
   "metadata": {},
   "source": [
    "The outcome is aligned with the XGBoost feature importance, however there is relatively smaller difference between LSTAT, RM and less important features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b31ea72c",
   "metadata": {},
   "source": [
    "### SHAP values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba08bd82",
   "metadata": {},
   "source": [
    "**Shapley values** is a concept from the game theory regarding fair distribution of the payout in a game with multiple players. The payout is calculated based on averaged contributions in all possible _coalitions_ (combinations of players taking part in the game). If we switch the notion of a player to a feature and payout to model's prediction the algorithm can be applied to interpret Machine Learning models.\n",
    "\n",
    "Shapley values are calculated on the prediction (local) level for each feature. The value can be interpreted as average contribution to the prediction compared to mean prediction over the whole dataset. To calculate contributions,  input observation is modified by removing the features  - analogous to absence of the players in a coalition. The predictions over all coalitions (feature combinations)  are gathered and an average 'payout' for each feature is calculated. \n",
    "\n",
    "An exact Shapley values calculation is compute-intensive as the number of coalitions increase exponentially with the number of feature, hence an approximate solution in the form of **SHAP values** is often used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4878cb8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "using ShapML\n",
    "using Flux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284a9692",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's train a black-box model for the SHAP values example\n",
    "# It's a simple neural with one dense hidden layer with ReLU activation function\n",
    "X_flux = transpose(X)\n",
    "y_flux = transpose(houses.medv)\n",
    "model = Chain(Dense(13 => 30, relu),  Dense(30 => 1))\n",
    "loss(x, y) = Flux.Losses.mse(model(x), y)\n",
    "parameters = Flux.params(model)\n",
    "data = [(X_flux, y_flux)]\n",
    "opt = Flux.Adam(0.005)\n",
    "for epoch in 1:30_000\n",
    "    Flux.train!(loss, parameters, data, opt)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2656a1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The R^2 should have a value around 90%\n",
    "R2(y_flux, model(X_flux))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47913827",
   "metadata": {},
   "outputs": [],
   "source": [
    "RMSE(y_flux, model(X_flux))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acee4bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "function predict_function(model, data)\n",
    "  data_pred = DataFrame(y_pred = vec(model(transpose(Matrix(data)))))\n",
    "  return data_pred\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8633ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating SHAP values for first observation\n",
    "# 600 random coalitions are tested instead of all combinations\n",
    "data_shap = ShapML.shap(explain = DataFrame(houses[1, Not(:medv)]),\n",
    "                        reference = houses[:, Not(:medv)],\n",
    "                        model = model,\n",
    "                        predict_function = predict_function,\n",
    "                        sample_size = 600,\n",
    "                        seed = 1\n",
    "                        )\n",
    "sort!(data_shap, :shap_effect);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3f19e5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "bar(data_shap.feature_name,\n",
    "    data_shap.shap_effect,\n",
    "    legend = nothing,\n",
    "    ylab = \"Shap effect\", \n",
    "    title = \"SHAP values for observation 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f62691",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHAP values for observation 42\n",
    "data_shap = ShapML.shap(explain = DataFrame(houses[42, Not(:medv)]),\n",
    "                        reference = houses[:, Not(:medv)],\n",
    "                        model = model,\n",
    "                        predict_function = predict_function,\n",
    "                        sample_size = 600,\n",
    "                        seed = 1\n",
    "                        )\n",
    "sort!(data_shap, :shap_effect);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5071e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "bar(data_shap.feature_name,\n",
    "    data_shap.shap_effect,\n",
    "    legend = nothing,\n",
    "    ylab = \"Shap effect\", \n",
    "    title = \"SHAP values for observation 42\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8adefa03",
   "metadata": {},
   "source": [
    "## XAI for unstructured data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b14689",
   "metadata": {},
   "source": [
    "We worked only with tabular data so far, but the multitude of novel AI applications use unstructured data such as image and text. In such applications, mainly deep neural networks are used as the shallow models doesn't have sufficient capacity for the task. Hence we may expect a black-box approach whenever dealing with unstructured data. \n",
    "\n",
    "Approach feasible for tabular data doesn't fit well for image or text datasets in the context of interpretability. Features can't be easily listed and assigned an importance. For each domain, XAI techniques focus on a specific features - in image recognition relevant pixels (or superpixels) may be highlighted, while in sentiment analysis the words contributing the most to the sentiment prediction.\n",
    "\n",
    "Some of the interpretability algorithms used on tabular data may be reused for unstructured datasets (e.g. [LIME](https://ema.drwhy.ai/LIME.html)), but there are also methods specific to each domain of the unstructred training. Often the specialised methods leverage the fact that the deep neural networks are based on gradient calculations, see for example [Integrated Gradients](https://www.tensorflow.org/tutorials/interpretability/integrated_gradients) or [SmoothGrad](https://arxiv.org/abs/1706.03825).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f5102c",
   "metadata": {},
   "source": [
    "We'll use a pretrained image classification model [VGG](https://arxiv.org/abs/1409.1556) on the image of main building of Warsaw School of Economics. After inspecting the classes predicted by the model, we'll utilize [LRP](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0130140) algorithm to mark the pixels which contributed the most to the obtained prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685dd43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Metalhead\n",
    "using ExplainableAI\n",
    "using FileIO\n",
    "using ImageShow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37962f80",
   "metadata": {},
   "source": [
    "![](./sgh.jpeg)\n",
    "\n",
    "A picture we'll use for image classifiation task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4c7e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "model = VGG(16, pretrain = true).layers\n",
    "model = strip_softmax(flatten_chain(model))\n",
    "\n",
    "#Load the list of Imagenet classes\n",
    "imagenet_classes = CSV.read(\"imagenet.csv\", DataFrame, delim = ';')\n",
    "\n",
    "# Load input\n",
    "input = preprocess_imagenet(load(\"sgh.jpeg\"))\n",
    "input = reshape(input, 224, 224, 3, :)\n",
    "\n",
    "# Create the LRP algorithm analyzer\n",
    "analyzer = LRP(model, EpsilonPlus());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd28416",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sort output classes based on the prediction probability\n",
    "best_classes = sortperm(vec(model(input)), rev = true);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e5f1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Main building of Warsaw School of Economics is classified as palace\n",
    "imagenet_classes[best_classes[1], :class_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6ba55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see which part of the picture were important for the prediction\n",
    "ExplainableAI.heatmap(input, analyzer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63829da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The second pick from the model is dome - quite accurate\n",
    "imagenet_classes[best_classes[2], :class_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e879ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ExplainableAI.heatmap(input, analyzer, best_classes[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d31c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The third pick is totally off - the closest sea is 250km away\n",
    "# Let's see why the model predicted that\n",
    "imagenet_classes[best_classes[3], :class_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c764da26",
   "metadata": {},
   "outputs": [],
   "source": [
    "ExplainableAI.heatmap(input, analyzer, best_classes[3])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.2",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
