{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f215af50",
   "metadata": {},
   "source": [
    "# Explaining The ML models - XAI (eXplainable AI)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "107c53b4",
   "metadata": {},
   "source": [
    "Interpretation techniques for the ML models focus on analysis how the input features (or change in their values) affect the predictions. Many classic models exhibit 'built-in' high interpretability, but the predictions of the complex models such as neural networks are opaque (hence the often used name 'black-box' models). \n",
    "\n",
    "In the recent years, explainability of the ML models (black-box in particular) became a popular topic and fueled many novel algorithms - the trend is often referred to as **Interpretable Machine Learning** or **Explainable Artificial Intelligence (XAI)**. \n",
    "\n",
    "Based on the applicability, the interpretability techniques can be categorised as follows:\n",
    " - **model-specific (intrinsic)** - tied to particular class of models, inherently available by design of the given algorithm e.g., linear regression, logistic regression, decision trees\n",
    " - **model-agnostic** - applicable to all ML models, mostly based on modifying the input data and 'probing' the influence on model's predictions or model's quality\n",
    "\n",
    "Additionally, the explainability algorithms may be broken down by the target they are applied to:\n",
    " - **prediction-level (local)** - provide explanation for prediction produced for a particular instance, useful if we want to understand the models behaviour on the per-case basis\n",
    " - **dataset-level (global)** - highlight overall feature influence on the model predictions\n",
    "\n",
    "Every interpretability technique is characterized by both breakdowns, so we may have a model-specific global technique, model-agnostic local algorithm, etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1197cb52",
   "metadata": {},
   "outputs": [],
   "source": [
    "using CSV, DataFrames\n",
    "using Random, Statistics\n",
    "using ExplainableAI, ShapML\n",
    "using ImageShow, Plots, FileIO\n",
    "using GLM, Flux, XGBoost, Metalhead\n",
    "using ProgressMeter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce802ef6",
   "metadata": {},
   "source": [
    "## Preparing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba045724",
   "metadata": {},
   "source": [
    "We'll use the dataset containing information about housing in the suburbs of Boston. You can find more information about the dataset in the [UCI repository](https://archive.ics.uci.edu/ml/machine-learning-databases/housing/). Data is available for ingestion in the **Boston.csv** file in the directory of the notebook.\n",
    "\n",
    "Attribute Information:\n",
    "\n",
    "1. CRIM - per capita crime rate by town\n",
    "2. ZN - proportion of residential land zoned for lots over 25,000 sq.ft.\n",
    "3. INDUS - proportion of non-retail business acres per town\n",
    "4. CHAS - Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
    "5. NOX - nitric oxides concentration (parts per 10 million)\n",
    "6. RM - average number of rooms per dwelling\n",
    "7. AGE - proportion of owner-occupied units built prior to 1940\n",
    "8. DIS - weighted distances to five Boston employment centres\n",
    "9. RAD - index of accessibility to radial highways\n",
    "10. TAX - full-value property-tax rate per \\$10,000\n",
    "11. PTRATIO - pupil-teacher ratio by town\n",
    "12. B - 1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
    "13. LSTAT - \\% lower status of the population\n",
    "14. MEDV - Median value of owner-occupied homes in \\$1000's"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e2305d",
   "metadata": {},
   "source": [
    "Let's load the data into a `DataFrame` and inspect the first observation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b7cf0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "houses = CSV.read(\"Boston.csv\", DataFrame)\n",
    "first(houses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ab3c11",
   "metadata": {},
   "source": [
    "The task is to predict the median house value (`medv`) based on all other available features. Let's remove the `Column1` containing observation ID and save the names of independent variables for further use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c5106e",
   "metadata": {},
   "outputs": [],
   "source": [
    "select!(houses, Not(:Column1))\n",
    "feature_names = names(houses, Not(:medv));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea16ddf2",
   "metadata": {},
   "source": [
    "## Models training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c321672d",
   "metadata": {},
   "source": [
    "Let's train three different models for the sake of interpretability analysis. Please note that we are not splitting the dataset into training, validation and test subsets as we are not picking the optimal specifications of the models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "574381d9",
   "metadata": {},
   "source": [
    " 1. Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d255c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_reg = lm(term(:medv) ~ sum(term.(feature_names)), houses);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5e3839",
   "metadata": {},
   "source": [
    " 2. Gradient Boosted Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64181277",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = Matrix(houses[!, Not(:medv)])\n",
    "y = houses.medv\n",
    "xgb_reg = xgboost(X, 30, label = y, objective = \"reg:squarederror\", seed = 42);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee7a52ba",
   "metadata": {},
   "source": [
    "3. Neural Network with one dense hidden layer with ReLU activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ffb5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_flux = transpose(X)\n",
    "y_flux = transpose(y)\n",
    "model = Chain(Dense(13 => 30, relu),  Dense(30 => 1))\n",
    "loss(x, y) = Flux.Losses.mse(model(x), y)\n",
    "parameters = Flux.params(model)\n",
    "data = [(X_flux, y_flux)]\n",
    "opt = Flux.Adam(0.005)\n",
    "@showprogress for epoch in 1:30_000\n",
    "    Flux.train!(loss, parameters, data, opt)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a405c8ec",
   "metadata": {},
   "source": [
    "We'll do a quick check of models predictive power on the training data. If the model fits poorly, the output of the interpretability algorithms is not representative and may lead to misleading conclusions. Let's use R² metric for the purpose of the test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274f849e",
   "metadata": {},
   "outputs": [],
   "source": [
    "R2(y, ŷ) = round(sum((ŷ .- mean(y)).^2)/sum((y .- mean(y)).^2); digits = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0d4f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Linear regression R²: \", R2(y, GLM.predict(lin_reg, houses)),\n",
    "\"\\nGradient boosted trees R²: \", R2(y, XGBoost.predict(xgb_reg, X)),\n",
    "\"\\nNeural network R²: \", R2(y_flux, model(X_flux)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca565f21",
   "metadata": {},
   "source": [
    "R² is very high for the neural network and gradient boosted trees (>0.9). Linear regression scores much lower (~0.7), but is still high and intepretability results shouldn't be significantly distorted."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c6cf01c",
   "metadata": {},
   "source": [
    "## Model-specific interpretability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4dfc5b",
   "metadata": {},
   "source": [
    "**Linear Regression** and the **Gradient Boosted Trees** are example of the models with 'built-in' (**inherent**) explainability.\n",
    "\n",
    "For the former, we can **directly interpret the values of the parameters** of the trained model - the approach is applicable to the whole family of [**Generalized Linear Models (GLMs)**](https://en.wikipedia.org/wiki/Generalized_linear_model) with appropiate transformations applied to the parameters and target variable values, e.g. logistic regression, Poisson regression.\n",
    "\n",
    "**Gradient Boosted Trees** is part of the bigger family of **tree-based models** (which includes various Decision Tree algorithms and ensemble models such as Random Forest). For the tree-based models, we can calculate a **feature importance** - the metric of the features contribution to the model's predictive power. The parameter values are not analysed directly, instead we are extracting a statistic (nodes impurity decrease) from the training process, which is relevant to understanding the model's decisions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd46eace",
   "metadata": {},
   "source": [
    "### Linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f447a63",
   "metadata": {},
   "source": [
    "Calling the variable with trained linear regression model produces a summary of the coefficients for interpretation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78fc9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_reg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c794f12",
   "metadata": {},
   "source": [
    "We can directly interpret calculated coefficients as the change in the predicted value (median house value in thousands of dollars) for a unit change in the value of the feature.\n",
    "\n",
    "For example, prediction of median house value will increase by 3 810 dollars with each additional room (`rm`) in the estate. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdfb474e",
   "metadata": {},
   "source": [
    "### Gradient Boosted Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca479a7",
   "metadata": {},
   "source": [
    "The `importance` function from the `XGBoost` package extracts features importance values from the given Gradient Boosted Trees model. Three importance measures are listed (Gain, Coverage and Frequency), but the most commonly used is Gain, which is the improvement in error reduction brought by a feature to the branches it is on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b349857",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_imp = importance(xgb_reg, feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d45cf6da",
   "metadata": {},
   "source": [
    "Let's compare feature importance (Gain) of all variables on the barplot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01cecda",
   "metadata": {},
   "outputs": [],
   "source": [
    "bar(getproperty.(f_imp, :fname), getproperty.(f_imp, :gain), \n",
    "    ylab = \"Feature gain\", legend = nothing, title = \"XGBoost feature importance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61083938",
   "metadata": {},
   "source": [
    "Based on the inherent feature importance two the most important features for the model predictions are `lstat` and `rm`. Note that the feature importance value doesn't indicate if the increase in the feature value corresponds to the increase in the target variable or otherwise."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd5f6ea",
   "metadata": {},
   "source": [
    "## Model-agnostic interpretability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6811fc",
   "metadata": {},
   "source": [
    "Model-agnostic algorithms may be applied on top of many Machine Learning models. The algorithms modify the input data and analyse the returned predictions - the inner architecture of the model is not relevant in that context. The model-agnostic techniques can be further divided into:\n",
    "\n",
    "Global techniques (explaining overall features effect on predictions):\n",
    "- [Partial Dependence Plots (PDP)](https://www.jstor.org/stable/2699986)\n",
    "- [Accumulated Local Effects (ALE)](https://arxiv.org/abs/1612.08468)\n",
    "- [Permutation-based feature importance](https://scikit-learn.org/stable/modules/permutation_importance.html)\n",
    "\n",
    "Local techniques (explaining particular prediction):\n",
    "- [Individual Conditional Expectations (ICE)](https://arxiv.org/abs/1309.6392)\n",
    "- [LIME (Local Interpretable Model-agnostic Explanations)](https://arxiv.org/abs/1602.04938)\n",
    "- [Shapley Values and SHAP (SHapley Additive exPlanations)](https://arxiv.org/abs/1705.07874)\n",
    "\n",
    "Let's explore one algorithm from each category: global **Permutation feature importance** and local **SHAP values**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ec9b76",
   "metadata": {},
   "source": [
    "### Permutation-based feature importance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed087df",
   "metadata": {},
   "source": [
    "The technique relies on measuring effect of breaking the relation between independent features and target variable. The idea is quite straightforward - if the important feature is randomly shuffled, the model performance should drop significantly, correspondingly for the not important feature the effect on the model's quality will be small. \n",
    "\n",
    "The algorithm can be applied to all models (model-agnostic) as it modify the data by shuffling the subsequent features and analyse the evaluation metric calculated based on predictions on the distorted data. Also the technique is global as it provides importance per feature on the whole dataset.\n",
    "\n",
    "Let's implement our own algorithm for permutation feature importance based on RMSE metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48c4dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "RMSE(y, ŷ) = sqrt(mean((y-ŷ).^2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6e97e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "function varimp(df::DataFrame, model, ref_rmse::Float64, reps::Int = 10, random_seed::Int = 1)\n",
    "    X = df[:, 1:end-1]\n",
    "    y = df[:, end]\n",
    "    features = names(X)\n",
    "    perm_feat_imp = []\n",
    "    for name in features\n",
    "        rmse = []\n",
    "        df_shuffle = copy(X)\n",
    "        for _ in 1:reps\n",
    "            Random.seed!(random_seed)\n",
    "            Random.shuffle!(df_shuffle[!, name])\n",
    "            if model isa Booster\n",
    "                prediction = XGBoost.predict(model, Matrix(df_shuffle))\n",
    "            elseif model isa StatsModels.TableRegressionModel\n",
    "                prediction = GLM.predict(model, hcat(df_shuffle, y))\n",
    "            elseif model isa Chain\n",
    "                prediction = transpose(model(transpose(Matrix(df_shuffle)))) \n",
    "            else\n",
    "                throw(DomainError(\"Unsupported model\"))\n",
    "            end\n",
    "            push!(rmse, RMSE(y, prediction))\n",
    "        end\n",
    "        rmse = rmse .- ref_rmse\n",
    "        push!(perm_feat_imp, (feature = name, rmse_change = mean(rmse), rmse_std = std(rmse)))\n",
    "    end\n",
    "    return sort!(DataFrame(perm_feat_imp), :rmse_change, rev = true)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "224f6183",
   "metadata": {},
   "source": [
    "Permutation-based feature importance for Gradient Boosted Trees. Firstly, we calculate the reference RMSE and specify the number of repetitions for each feature. The results from the algorithm are presented on the barplot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80021e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_rmse = RMSE(y, XGBoost.predict(xgb_reg, X))\n",
    "reps = 20\n",
    "perm_feat_imp = varimp(houses, xgb_reg, xgb_rmse, reps, 42);\n",
    "bar(perm_feat_imp.feature,\n",
    "    perm_feat_imp.rmse_change,\n",
    "    yerr = perm_feat_imp.rmse_std,\n",
    "    legend = nothing,\n",
    "    ylab = \"RMSE change\", \n",
    "    title = \"XGBoost\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d644efa6",
   "metadata": {},
   "source": [
    "The outcome is aligned with the XGBoost feature importance, however there is relatively smaller difference between `lstat`, `rm` and less important features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6a3111",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_rmse = RMSE(y, transpose(model(X_flux)))\n",
    "perm_feat_imp = varimp(houses, model, nn_rmse, reps, 42)\n",
    "bar(perm_feat_imp.feature,\n",
    "    perm_feat_imp.rmse_change,\n",
    "    yerr = perm_feat_imp.rmse_std,\n",
    "    legend = nothing,\n",
    "    ylab = \"RMSE change\", \n",
    "    title = \"Neural Network\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb1b250",
   "metadata": {},
   "source": [
    "In case of neural network `tax` is by far the most important - the feature was much less important in case of Gradient Boosted Trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0bf03d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_rmse = RMSE(y, GLM.predict(lin_reg, houses))\n",
    "perm_feat_imp = varimp(houses, lin_reg, lr_rmse, reps, 42)\n",
    "bar(perm_feat_imp.feature,\n",
    "    perm_feat_imp.rmse_change,\n",
    "    yerr = perm_feat_imp.rmse_std,\n",
    "    legend = nothing,\n",
    "    ylab = \"RMSE change\", \n",
    "    title = \"Linear Regression\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e950d702",
   "metadata": {},
   "source": [
    "For linear regression `lstat` and `rm` are also important as in the Boosted Trees case, but additionally `dis` is second in terms of RMSE change. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b31ea72c",
   "metadata": {},
   "source": [
    "### SHAP values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba08bd82",
   "metadata": {},
   "source": [
    "**Shapley values** is a concept from the game theory regarding fair distribution of the payout in a game with multiple players. The payout is calculated based on averaged contributions in all possible _coalitions_ (combinations of players taking part in the game). If we switch the notion of a player to a feature and payout to model's prediction the algorithm can be applied to interpret Machine Learning models.\n",
    "\n",
    "Shapley values are calculated on the prediction (local) level for each feature. The value can be interpreted as average contribution to the prediction compared to mean prediction over the whole dataset. To calculate contributions,  input observation is modified by removing the features  - analogous to absence of the players in a coalition. The predictions over all coalitions (feature combinations)  are gathered and an average 'payout' for each feature is calculated. \n",
    "\n",
    "An exact Shapley values calculation is compute-intensive as the number of coalitions increase exponentially with the number of feature, hence an approximate solution in the form of **SHAP values** is often used."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5cda81",
   "metadata": {},
   "source": [
    "We need to prepare the auxilary prediction function as an input for SHAP values calculation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acee4bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "function predict_function(model, data)\n",
    "    if model isa Booster\n",
    "        prediction = XGBoost.predict(model, Matrix(data))\n",
    "    elseif model isa StatsModels.TableRegressionModel\n",
    "        data.medv .= 1\n",
    "        prediction = GLM.predict(model, data)\n",
    "    elseif model isa Chain\n",
    "        prediction = vec(model(transpose(Matrix(data)))) \n",
    "    else\n",
    "        throw(DomainError(\"Unsupported model\"))\n",
    "    end\n",
    "    return DataFrame(y_pred = prediction)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065b975d",
   "metadata": {},
   "source": [
    "Calculating SHAP values for the first observation. 1000 random coalitions are tested instead of all combinations. The result from the algorithm is sorted and plotted for easier interpretation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f44757",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = houses[:, Not(:medv)]\n",
    "observation = DataFrame(houses[1, Not(:medv)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c4f954",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_shap = ShapML.shap(explain = observation, reference = X, model = xgb_reg,\n",
    "                        predict_function = predict_function, sample_size = 1000, seed = 1)\n",
    "sort!(data_shap, :shap_effect)\n",
    "bar(data_shap.feature_name,\n",
    "    data_shap.shap_effect,\n",
    "    legend = nothing,\n",
    "    ylab = \"Shap effect\", \n",
    "    title = \"SHAP values for observation 1 - XGBoost\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5934beb9",
   "metadata": {},
   "source": [
    "`lstat` is by far the most important feature for the first observation. `lstat` value in the analysed observation (4.98) is much lower than the feature's average (12.65) and due to that contributes around 5000$ to the median house value. Such high reliance on the `lstat` may indicate overfitting issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8633ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_shap = ShapML.shap(explain = observation, reference = X, model = model,\n",
    "                        predict_function = predict_function, sample_size = 1000, seed = 1)\n",
    "sort!(data_shap, :shap_effect)\n",
    "bar(data_shap.feature_name,\n",
    "    data_shap.shap_effect,\n",
    "    legend = nothing,\n",
    "    color = \"orange\",\n",
    "    ylab = \"Shap effect\", \n",
    "    title = \"SHAP values for observation 1 - Neural Network\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea4c293a",
   "metadata": {},
   "source": [
    "For neural network the contribution distribution is different. `lstat` is still important, but `rad` has the highest influence on the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84665d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_shap = ShapML.shap(explain = observation, reference = X, model = lin_reg,\n",
    "                        predict_function = predict_function, sample_size = 1000, seed = 1)\n",
    "sort!(data_shap, :shap_effect)\n",
    "bar(data_shap.feature_name,\n",
    "    data_shap.shap_effect,\n",
    "    legend = nothing,\n",
    "    color = \"green\",\n",
    "    ylab = \"Shap effect\", \n",
    "    title = \"SHAP values for observation 1 - Linear Regression\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aeb357c",
   "metadata": {},
   "source": [
    "SHAP values for linear regression are somewhere in between results for neural network and boosted trees."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8adefa03",
   "metadata": {},
   "source": [
    "## XAI for unstructured data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b14689",
   "metadata": {},
   "source": [
    "We worked only with tabular data so far, but the multitude of novel AI applications use unstructured data such as image and text. In such applications, mainly deep neural networks are used as the shallow models doesn't have sufficient capacity for the task. Hence we may expect a black-box approach whenever dealing with unstructured data. \n",
    "\n",
    "Approach feasible for tabular data doesn't fit well for image or text datasets in the context of interpretability. Features can't be easily listed and assigned an importance. For each domain, XAI techniques focus on a specific features - in image recognition relevant pixels (or superpixels) may be highlighted, while in sentiment analysis the words contributing the most to the sentiment prediction.\n",
    "\n",
    "Some of the interpretability algorithms used on tabular data may be reused for unstructured datasets (e.g. [LIME](https://ema.drwhy.ai/LIME.html)), but there are also methods specific to each domain of the unstructred training. Often the specialised methods leverage the fact that the deep neural networks are based on gradient calculations, see for example [Integrated Gradients](https://www.tensorflow.org/tutorials/interpretability/integrated_gradients) or [SmoothGrad](https://arxiv.org/abs/1706.03825).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f5102c",
   "metadata": {},
   "source": [
    "We'll use a pretrained image classification model [VGG](https://arxiv.org/abs/1409.1556) on the image of main building of Warsaw School of Economics. After inspecting the classes predicted by the model, we'll utilize [LRP](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0130140) algorithm to mark the pixels which contributed the most to the obtained prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37962f80",
   "metadata": {},
   "source": [
    "![](./sgh.jpeg)\n",
    "\n",
    "A picture we'll use for image classifiation task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3520fff0",
   "metadata": {},
   "source": [
    "Load the VGG model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da821c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VGG(16, pretrain = true).layers;\n",
    "# model = strip_softmax(flatten_chain(model));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a69c00c6",
   "metadata": {},
   "source": [
    "Load the list of Imagenet target classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4c7e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "imagenet_classes = CSV.read(\"imagenet.csv\", DataFrame, delim = ';');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503e1f7c",
   "metadata": {},
   "source": [
    "Load the input image `sgh.jpeg`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa395b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = preprocess_imagenet(load(\"sgh.jpeg\"))\n",
    "input = reshape(input, 224, 224, 3, :);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef8a97e",
   "metadata": {},
   "source": [
    "Sort output classes based on the prediction probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd28416",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_classes = sortperm(vec(model(input)), rev = true);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc31829",
   "metadata": {},
   "source": [
    "Main building of Warsaw School of Economics is classified as palace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e5f1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "imagenet_classes[best_classes[1], :class_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccac7bcf",
   "metadata": {},
   "source": [
    "Let's see which parts of the picture were important for the prediction (red elements on the heatmap)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6ba55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer = LRP(model, EpsilonPlus())\n",
    "ExplainableAI.heatmap(input, analyzer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc3a6e1",
   "metadata": {},
   "source": [
    "The second pick from the model is a dome - quite accurate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63829da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "imagenet_classes[best_classes[2], :class_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d30be609",
   "metadata": {},
   "source": [
    "Let's highlight important elements of the photograph again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e879ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ExplainableAI.heatmap(input, analyzer, best_classes[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef1436c7",
   "metadata": {},
   "source": [
    "The third pick is totally off - the closest sea is 250km away.\n",
    "\n",
    "Let's see why the model predicted that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d31c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "imagenet_classes[best_classes[3], :class_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c764da26",
   "metadata": {},
   "outputs": [],
   "source": [
    "ExplainableAI.heatmap(input, analyzer, best_classes[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ca25e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.2",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
